{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Visualization Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Answer business requirement 1: \n",
        "    * As a customer I am interested to understand the patterns from my customer base, so I can better manage churn levels.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate code that answers business requirement 1 and can be used to build Streamlit App\n",
        "\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGT0ZCtwFAFv"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcidnQspZztu"
      },
      "source": [
        "! pip install pandas-profiling==2.11.0\n",
        "! pip install plotly==4.14.0\n",
        "! pip install feature-engine==1.0.2\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n",
        "  * Typically the output will be /device:GPU:0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WicMedgXzMgS"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Uczzm_zXI4"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1q2QBwkcIH2"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6jYL7Crh3an"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtMP7Pjvwpm2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPPGQ3xa0dH1"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4V8x_AF1Euv"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fOslPfih6Qn"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTydg5Xwqiu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5uhLCk0lUJ"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3ns1Tl0_MS"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRImgZx7h-WY"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcmA1wG8AdC"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Nrg1IgeQMD"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1kUQ0VIoi4c"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dafOBor8OoM"
      },
      "source": [
        "CommitMsg = \"added-cleaned-data\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkyUs70oloW"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0NCb8-L8Vr1"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0LAtX71A9ob"
      },
      "source": [
        "check if all files are image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBrWBiRGA6Th"
      },
      "source": [
        "\n",
        "import os\n",
        "def remove_non_image_file(my_data_dir):\n",
        "\n",
        "  image_extension = ('.png', '.jpg', '.jpeg','.tiff')\n",
        "  folders = os.listdir(my_data_dir) \n",
        "  for folder in folders:\n",
        "    files = os.listdir(my_data_dir + '/' + folder)\n",
        "    for given_file in files:\n",
        "      if not given_file.lower().endswith(image_extension):\n",
        "        file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "        # print(file_location)\n",
        "        os.remove(file_location)\n",
        "        print(f\"Folder: {folder} - Removed File: {given_file}\")\n",
        "  \n",
        "  print(f\"\\nRemoved files that don't have one of these extensions: {image_extension}\")\n",
        "\n",
        "\n",
        "my_data_dir = '/content/WalkthroughProject01/inputs/data'\n",
        "my_data_dir = '/content/WalkthroughProject01/inputs/datasets/cell_images/cell_images'\n",
        "remove_non_image_file(my_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNCWyaBZA6p3"
      },
      "source": [
        "split train test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK8ShA1FctI6"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_test_images(my_data_dir, train_set_ratio=0.7):\n",
        "\n",
        "  # gets classes labels\n",
        "  labels = os.listdir(my_data_dir) # it should get only the folder name\n",
        "\n",
        "\n",
        "  # create train, test folders with classess labels sub-folder\n",
        "  for folder in ['train','test']:\n",
        "    for label in labels:\n",
        "      os.makedirs(name=my_data_dir+'/'+folder + '/' + label)\n",
        "\n",
        "  for label in labels:\n",
        "\n",
        "    files = os.listdir(my_data_dir + '/' + label)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_set_ratio = 0.7\n",
        "    train_set_files = int(len(files) * train_set_ratio)\n",
        "\n",
        "    count = 1\n",
        "    for file_name in  files:\n",
        "      if count <= train_set_files:\n",
        "        shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                    my_data_dir + '/train/' + label + '/' + file_name)\n",
        "\n",
        "      else:\n",
        "        shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                my_data_dir + '/test/' +label + '/'+ file_name)\n",
        "        \n",
        "      count += 1\n",
        "\n",
        "    os.rmdir(my_data_dir + '/' + label)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "split_train_test_images(my_data_dir = '/content/WalkthroughProject01/inputs/data',\n",
        "                        train_set_ratio=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPOz0yhecOx"
      },
      "source": [
        "split_train_test_images(my_data_dir = '/content/WalkthroughProject01/inputs/datasets/cell_images/cell_images',\n",
        "                        train_set_ratio=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3DUHBGThBzt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXTuEOt2c3E"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqqga261_w4N"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntzIpcxb3oIE"
      },
      "source": [
        "my_data_dir = '/content/WalkthroughProject01/inputs/datasets/cell_images/cell_images'\n",
        "labels_train = os.listdir(my_data_dir+ '/train')\n",
        "labels_test = os.listdir(my_data_dir+ '/test')\n",
        "\n",
        "labels = set(labels_train, labels_test) # ???\n",
        "print(labels_train,labels_test,labels)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eucaA9M6qz1"
      },
      "source": [
        "train_path = my_data_dir + '/train'\n",
        "test_path = my_data_dir + '/test'\n",
        "train_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSTKDM0XvuVu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ0p1nYJ_3sx"
      },
      "source": [
        "check classes distribution on train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeOv0tCn3_Y_"
      },
      "source": [
        "for folder in ['train', 'test']:\n",
        "  for label in labels:\n",
        "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4l-B11vCiP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7aDMBdY_6lQ"
      },
      "source": [
        "quick viz on 1 image from either train/test, from one of the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMQVJmyC4IX4"
      },
      "source": [
        "pointer = 5\n",
        "para_img = imread(train_path + '/'+ labels[1]+ '/'+ os.listdir(train_path+'/'+labels[1])[pointer])\n",
        "print(para_img.shape)\n",
        "plt.imshow(para_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50dLF5DgBqKK"
      },
      "source": [
        "load randomly a image from a given directory and plot on image montage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT5yvEwJByYR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPPUGkhDByma"
      },
      "source": [
        "avg/std image from each label, avg/std diff bewteen labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7SjfmiaB7Px"
      },
      "source": [
        "# have to resize images\n",
        "# have to load images into a array, but they shouold have same dimensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLIonZOXB7XR"
      },
      "source": [
        "# load images from a folder\n",
        "\n",
        "X = np.array([])\n",
        "y = pd.Series([]) # or array?\n",
        "# loop over train/test path\n",
        "# load images, store on img_aux\n",
        "# append img_aux to X\n",
        "# append label to y  \n",
        "\n",
        "# will not work?? images have different size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znybb5lQvx5o"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OptI7pnA6zPZ"
      },
      "source": [
        "image sizes on train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00W_ROgJ71a-"
      },
      "source": [
        "dim1,dim2 = [], []\n",
        "for label in labels:\n",
        "  for image_filename in os.listdir(train_path+ '/'+ label):\n",
        "    try:\n",
        "      img = imread(train_path+ '/'+ label + '/'+ image_filename)\n",
        "      d1, d2, colors = img.shape\n",
        "      dim1.append(d1)\n",
        "      dim2.append(d2)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots()\n",
        "sns.scatterplot(x=dim1, y=dim2, alpha=0.2)\n",
        "dim1_mean = int(np.array(dim1).mean())\n",
        "dim2_mean = int(np.array(dim2).mean())\n",
        "axes.axvline(x=dim1_mean,color='r', linestyle='--')\n",
        "axes.axhline(y=dim2_mean,color='r', linestyle='--')\n",
        "plt.show()\n",
        "print(f\"dim1 average: {dim1_mean}\\ndim average: {dim2_mean}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaWVery3Afa8"
      },
      "source": [
        "image_shape = (dim2_mean,dim1_mean,3)\n",
        "image_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hidGo-uhBq1L"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GbzYwjk_-_E"
      },
      "source": [
        "data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMU8_F6ZAfjS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIkD9esZAhTm"
      },
      "source": [
        "image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n",
        "                               width_shift_range=0.10, # Shift the pic width by a max of 5%\n",
        "                               height_shift_range=0.10, # Shift the pic height by a max of 5%\n",
        "                               rescale=1/255, # Rescale the image by normalzing it.\n",
        "                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n",
        "                               zoom_range=0.1, # Zoom in by 10% max\n",
        "                               horizontal_flip=True, # Allo horizontal flipping\n",
        "                               fill_mode='nearest', # Fill in missing pixels with the nearest filled value\n",
        "                               validation_split=0.2,      \n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-OV-AtyAhW0"
      },
      "source": [
        "plt.imshow(para_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJqnauMApW4"
      },
      "source": [
        "plt.imshow(image_gen.random_transform(para_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aw_g3aIBsZG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iuex24NSABg6"
      },
      "source": [
        "# create model\n",
        "#fit model, use tensorboard,with hyperparameter opitimization\n",
        "# evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3em0FUWzBTCF"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32)) # 128\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
        "# Here we say randomly turn off 50% of neurons.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Last layer, remember its binary so we use sigmoid\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0fnaUSeBTFy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bP61QYBTMF"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNemQ_4HChz9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ7o8oJ3B3wE"
      },
      "source": [
        "batch_size = 16\n",
        "train_image_gen = image_gen.flow_from_directory(train_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                                color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='binary')\n",
        "\n",
        "train_image_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9EN8Q8BCsLR"
      },
      "source": [
        "test_image_gen = image_gen.flow_from_directory(test_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                               color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='binary',shuffle=False)\n",
        "\n",
        "test_image_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHD-ggqiB3zV"
      },
      "source": [
        "results = model.fit_generator(train_image_gen,epochs=4,\n",
        "                              validation_data=test_image_gen,\n",
        "                              callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQoAE4uNB34l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTm0tI1VB3-C"
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGDLfdaiB4IH"
      },
      "source": [
        "losses[['loss','val_loss']].plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3f7AqrkzhH5"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ-hkWgoziwT"
      },
      "source": [
        "model.evaluate_generator(test_image_gen)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}