{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Visualization Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Answer business requirement 1: \n",
        "    * As a customer I am interested to understand the patterns from my customer base, so I can better manage churn levels.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate code that answers business requirement 1 and can be used to build Streamlit App\n",
        "\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGT0ZCtwFAFv"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEYlHLZ-Hm51"
      },
      "source": [
        "! pip install tensorflow==2.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcidnQspZztu"
      },
      "source": [
        "# ! pip install pandas-profiling==2.11.0\n",
        "# ! pip install plotly==4.14.0\n",
        "# ! pip install feature-engine==1.0.2\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n",
        "  * Typically the output will be /device:GPU:0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WicMedgXzMgS"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Uczzm_zXI4"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1q2QBwkcIH2"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6jYL7Crh3an"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtMP7Pjvwpm2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPPGQ3xa0dH1"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4V8x_AF1Euv"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fOslPfih6Qn"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTydg5Xwqiu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5uhLCk0lUJ"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3ns1Tl0_MS"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRImgZx7h-WY"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uyhWwn8RpZ2"
      },
      "source": [
        "Quick Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqqga261_w4N"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntzIpcxb3oIE"
      },
      "source": [
        "# my_data_dir = '/content/WalkthroughProject01/inputs/datasets/cell_images/cell_images'\n",
        "# my_data_dir = '/content/WalkthroughProject01/inputs/little_train_set/cell_images'\n",
        "my_data_dir = f\"/content/{os.environ['RepoName']}/inputs/malaria_dataset/cell_images\"\n",
        "\n",
        "labels_train = os.listdir(my_data_dir+ '/train')\n",
        "labels_val = os.listdir(my_data_dir+ '/validation')\n",
        "labels_test = os.listdir(my_data_dir+ '/test')\n",
        "labels = list(set(labels_train + labels_test))\n",
        "\n",
        "print(\n",
        "    f\"Labels on train set: {labels_train}\\n\"\n",
        "    f\"Labels on validation set: {labels_val}\\n\"\n",
        "    f\"Labels on test set: {labels_test}\\n\"\n",
        "    f\"Project Labels: {labels}\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eucaA9M6qz1"
      },
      "source": [
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'\n",
        "train_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSTKDM0XvuVu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ0p1nYJ_3sx"
      },
      "source": [
        "## Check labels frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeOv0tCn3_Y_"
      },
      "source": [
        "df_freq = pd.DataFrame([]) \n",
        "for folder in ['train', 'validation', 'test']:\n",
        "  for label in labels:\n",
        "    df_freq = df_freq.append(\n",
        "        pd.Series(data={'Set': folder,\n",
        "                        'Label': label,\n",
        "                        'Frequency':int(len(os.listdir(my_data_dir+'/'+ folder + '/' + label)))}\n",
        "                  ),\n",
        "                  ignore_index=True\n",
        "        )\n",
        "    \n",
        "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp4l-B11vCiP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY_hNVkYR2k6"
      },
      "source": [
        "## Image montage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3HqArMgR4Bq"
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "# logic\n",
        "# if label exists in the folder\n",
        "  # check if your montage space is greater tha nsubset size\n",
        "  # create list of axes indices based on nrows and ncols\n",
        "  # create a Figure and display images\n",
        "    # in this loop, load and plot given image\n",
        "\n",
        "\n",
        "def image_montage(dir_path, label_to_display, nrows, ncols, figsize=(15,10)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  labels = os.listdir(dir_path)\n",
        "\n",
        "  # subset the class you are interested to display\n",
        "  if label_to_display in labels:\n",
        "\n",
        "    # checks if your montage space is greater than subset size\n",
        "    images_list = os.listdir(dir_path+'/'+ label_to_display)\n",
        "    if nrows * ncols < len(images_list):\n",
        "      img_idx = random.sample(images_list, nrows * ncols)\n",
        "    else:\n",
        "      print(\n",
        "          f\"Decrease nrows or ncols to create your montage. \\n\"\n",
        "          f\"There are {len(images_list)} in your subset. \"\n",
        "          f\"You requested a montage with {nrows * ncols} spaces\")\n",
        "      return\n",
        "    \n",
        "\n",
        "    # create list of axes indices based on nrows and ncols\n",
        "    list_rows= range(0,nrows)\n",
        "    list_cols= range(0,ncols)\n",
        "    plot_idx = list(itertools.product(list_rows,list_cols))\n",
        "\n",
        "\n",
        "    # create a Figure and display images\n",
        "    fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=figsize)\n",
        "    for x in range(0,nrows*ncols):\n",
        "      img = imread(dir_path + '/' + label_to_display + '/' + img_idx[x])\n",
        "      img_shape = img.shape\n",
        "      axes[plot_idx[x][0], plot_idx[x][1]].imshow(img)\n",
        "      axes[plot_idx[x][0], plot_idx[x][1]].set_title(f\"Width {img_shape[1]}px x Height {img_shape[0]}px\")\n",
        "      axes[plot_idx[x][0], plot_idx[x][1]].set_xticks([])\n",
        "      axes[plot_idx[x][0], plot_idx[x][1]].set_yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  else:\n",
        "    print(\"The label you selected doesn't exist.\")\n",
        "    print(f\"The existing options are: {labels}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L11xz9p6S3A5"
      },
      "source": [
        "for label in labels:\n",
        "  print(label)\n",
        "  image_montage(dir_path= train_path,\n",
        "                label_to_display= label,\n",
        "                nrows=6, ncols=3, figsize=(10,15))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INSoNmInR3UP"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7aDMBdY_6lQ"
      },
      "source": [
        "quick viz on 1 image from either train/test, from one of the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgRfdOid0j1X"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMQVJmyC4IX4"
      },
      "source": [
        "pointer = 44\n",
        "para_img = imread(train_path + '/'+ labels[0]+ '/'+ os.listdir(train_path+'/'+labels[0])[pointer])\n",
        "print(para_img.shape)\n",
        "sns.set_style(\"white\")\n",
        "plt.imshow(para_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PjC22BTyOLU"
      },
      "source": [
        "para_img.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lE1vYxK13VE"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BHzBBt-5fEh"
      },
      "source": [
        "## Avg and Std images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOouyToAKFyB"
      },
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/eda//{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OptI7pnA6zPZ"
      },
      "source": [
        "image sizes on train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00W_ROgJ71a-"
      },
      "source": [
        "dim1, dim2 = [], []\n",
        "for label in labels:\n",
        "  for image_filename in os.listdir(train_path + '/'+ label):\n",
        "    img = imread(train_path + '/'+ label + '/'+ image_filename)\n",
        "    d1, d2, colors = img.shape\n",
        "    dim1.append(d1) # image height\n",
        "    dim2.append(d2) # image width\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots()\n",
        "sns.scatterplot(x=dim2, y=dim1, alpha=0.2)\n",
        "axes.set_xlabel(\"Width (pixels)\")\n",
        "axes.set_ylabel(\"Height (pixels)\")\n",
        "dim1_mean = int(np.array(dim1).mean())\n",
        "dim2_mean = int(np.array(dim2).mean())\n",
        "axes.axvline(x=dim1_mean,color='r', linestyle='--')\n",
        "axes.axhline(y=dim2_mean,color='r', linestyle='--')\n",
        "plt.show()\n",
        "print(f\"Width average: {dim2_mean} \\nHeight average: {dim1_mean}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwcDKE7z577p"
      },
      "source": [
        "Shape for resized image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaWVery3Afa8"
      },
      "source": [
        "image_shape = (dim1_mean, dim2_mean, 3)\n",
        "image_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPPUGkhDByma"
      },
      "source": [
        "avg/std image from each label, avg/std diff bewteen labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qkw_I0B6CYO"
      },
      "source": [
        "import cv2\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "def resize_images(my_data_dir, new_size=(50,50)):\n",
        "  \n",
        "  X, y = np.array([], dtype='int'), np.array([], dtype='object')\n",
        "  labels = os.listdir(my_data_dir)\n",
        "\n",
        "  for label in labels:\n",
        "    aux = 0\n",
        "    # print(f\"{label}\\n\")\n",
        "    for image_filename in os.listdir(my_data_dir + '/' + label):\n",
        "      if aux < 20:\n",
        "        img = imread(my_data_dir + '/' + label + '/' + image_filename)\n",
        "        img_resized = cv2.resize(img,(new_size[0], new_size[1]))\n",
        "        X = np.append(X, img_resized).reshape(-1, new_size[0], new_size[1], img_resized.shape[2])\n",
        "        y = np.append(y, label)\n",
        "        # print(img_resized.shape)\n",
        "        aux = aux + 1\n",
        "  #   print(X.shape)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "\n",
        "X, y = resize_images(my_data_dir=train_path, new_size=(dim2_mean,dim1_mean))\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtML5vDG_VLQ"
      },
      "source": [
        "for x in range(0,400,25):\n",
        "  print(x, y[x])\n",
        "  plt.imshow(X[x])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DicOpvVCCS3X"
      },
      "source": [
        "image_average_and_variability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th7WOb4bCSLp"
      },
      "source": [
        "def image_average_and_variability(X, y, figsize=(12,5)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  for class_to_display in np.unique(y):\n",
        "    y = y.reshape(-1,1,1)\n",
        "    boolean_mask = np.any(y==class_to_display,axis=1).reshape(-1)\n",
        "    df = X[boolean_mask]\n",
        "    avg_img = np.mean(df, axis = 0)\n",
        "    std_img = np.std(df, axis = 0)\n",
        "    print(f\"==== Class {class_to_display} ====\")\n",
        "    print(avg_img.shape)\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "    axes[0].set_title(f\"Average Image for class {class_to_display}\")\n",
        "    axes[0].imshow(avg_img)\n",
        "    axes[1].set_title(f\"Standard Deviation for class {class_to_display}\")\n",
        "    axes[1].imshow(std_img)\n",
        "    # plt.savefig(f'{file_path}/avg_std_img_{class_to_display}.png', bbox_inches='tight', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\")\n",
        "  \n",
        "\n",
        "# for standard deviation, the lighter area indicates higher variability in that class\n",
        "image_average_and_variability(X=X, y=y, figsize=(12,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX8Q_XDMCYkv"
      },
      "source": [
        "contrast_between_2_classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui2SURsvCYzm"
      },
      "source": [
        "def subset_image_class(X,y,class_to_display):\n",
        "  y = y.reshape(-1,1,1)\n",
        "  boolean_mask = np.any(y==class_to_display,axis=1).reshape(-1)\n",
        "  df = X[boolean_mask]\n",
        "  return df\n",
        "\n",
        "def contrast_between_2_classes(X, y, class_1, class_2, figsize=(12,5)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  # what if images have different sizes?\n",
        "\n",
        "  if (class_1 not in np.unique(y)) or (class_2 not in np.unique(y)):\n",
        "    print(f\"Either class {class_1} or class {class_2}, are not in {np.unique(y)} \")\n",
        "    return\n",
        "\n",
        "  # calculate mean from class1\n",
        "  images_class_1 = subset_image_class(X, y, class_1)\n",
        "  class1_avg = np.mean(images_class_1, axis = 0)\n",
        "\n",
        "  # calculate mean from class2\n",
        "  images_class_2 = subset_image_class(X, y, class_2)\n",
        "  class2_avg = np.mean(images_class_2, axis = 0)\n",
        "\n",
        "  # calculate difference and plot all\n",
        "  contrast_mean = class1_avg - class2_avg\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=3,figsize=figsize)\n",
        "  axes[0].imshow(contrast_mean)\n",
        "  axes[0].set_title(f'Difference Between Avg: {class_1} & {class_2}')\n",
        "  axes[1].imshow(class1_avg)\n",
        "  axes[1].set_title(f'Average Class {class_1}')\n",
        "  axes[2].imshow(class2_avg)\n",
        "  axes[2].set_title(f'Average Class {class_2}')\n",
        "  # plt.savefig(f\"{file_path}/avg_diff.png\", bbox_inches='tight', dpi=150)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "contrast_between_2_classes(X=X, y=y, class_1='Parasitized', class_2='Uninfected', figsize=(12,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4aFxZBWCbYr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7SjfmiaB7Px"
      },
      "source": [
        "https://towardsdatascience.com/tagged/resize-images?p=3e0f29b992be\n",
        "https://towardsdatascience.com/what-is-the-best-input-pipeline-to-train-image-classification-models-with-tf-keras-eb3fe26d3cc5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hidGo-uhBq1L"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qved3ALYLrng"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a2rw6FuEnrV"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3em0FUWzBTCF"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
        "# Here we say randomly turn off 50% of neurons.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Last layer, remember its binary so we use sigmoid\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0fnaUSeBTFy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bP61QYBTMF"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aw_g3aIBsZG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huUhoI4-V4Wj"
      },
      "source": [
        "train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMU8_F6ZAfjS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIkD9esZAhTm"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=20,\n",
        "                                   width_shift_range=0.10, \n",
        "                                   height_shift_range=0.10,\n",
        "                                   shear_range=0.1,\n",
        "                                   zoom_range=0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest',     \n",
        "                              )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08qYmeq3FE-e"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                              target_size=image_shape[:2],\n",
        "                                              color_mode='rgb',\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='binary',\n",
        "                                              shuffle=True\n",
        "                                              )\n",
        "\n",
        "train_set.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cAwum1tWsmz"
      },
      "source": [
        "validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi6LZ9oJMPHB"
      },
      "source": [
        "validation_set = ImageDataGenerator().flow_from_directory(val_path,\n",
        "                                                          target_size=image_shape[:2],\n",
        "                                                          color_mode='rgb',\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          class_mode='binary',\n",
        "                                                          shuffle=False\n",
        "                                                          )\n",
        "\n",
        "validation_set.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDzlWdBXGGI"
      },
      "source": [
        "test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egJ0XQSkQZ7i"
      },
      "source": [
        "test_set = ImageDataGenerator().flow_from_directory(test_path,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    color_mode='rgb',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle=False\n",
        "                                                    )\n",
        "\n",
        "test_set.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Sv_Nlfzr5F"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHD-ggqiB3zV"
      },
      "source": [
        "model.fit(train_set,\n",
        "          epochs=20,\n",
        "          steps_per_epoch = len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop])\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')\n",
        "\n",
        "# model.save('/content/WalkthroughProject01/outputs/model/model_wt01_full_train_set.h5')\n",
        "\n",
        "# CommitMsg = \"update\"\n",
        "# !git add .\n",
        "# !git commit -m {CommitMsg}\n",
        "# !git push origin main\n",
        "\n",
        "# started at 14:14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uESgICbOztUi"
      },
      "source": [
        "model training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGDLfdaiB4IH"
      },
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss','val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy','val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RtitT7v-xv"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I41227LlqtV"
      },
      "source": [
        "evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3f7AqrkzhH5"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DABUpiZckeCL"
      },
      "source": [
        "model.evaluate(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ-hkWgoziwT"
      },
      "source": [
        "model.evaluate(validation_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py-xMpv0kZXU"
      },
      "source": [
        "model.evaluate(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MxRr9CcRjI7"
      },
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# model1 = load_model('outputs/model/malaria_detector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdS4f-2VAp-J"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "def model_evaluation(model, image_generator):\n",
        "  pred_probabilities = model.predict(image_generator)\n",
        "  predictions = pred_probabilities > 0.5\n",
        "\n",
        "  pd.Series(pred_probabilities.flatten()).hist()\n",
        "  plt.show()\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print(classification_report(image_generator.classes,predictions))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  Map = image_generator.class_indices\n",
        "  print(pd.DataFrame(confusion_matrix(predictions,image_generator.classes),\n",
        "        columns=[ [\"Actual \" + sub for sub in Map] ], \n",
        "        index = [ [\"Prediction \" + sub for sub in Map ]]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dsaUbtSlK8V"
      },
      "source": [
        "train_set_shuffle_false = ImageDataGenerator().flow_from_directory(train_path,\n",
        "                                                          target_size=image_shape[:2],\n",
        "                                                          color_mode='rgb',\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          class_mode='binary',\n",
        "                                                          shuffle=False\n",
        "                                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJ2hHZvTqQ-"
      },
      "source": [
        "import datetime\n",
        "for image_set in [train_set_shuffle_false, validation_set, test_set]:\n",
        "  \n",
        "  print(f'{image_set.directory.split(\"/\")[-1]} set')\n",
        "  a = datetime.datetime.now()\n",
        "\n",
        "  model_evaluation(model=model, image_generator=image_set)\n",
        "  print(f'\\nTime for evaluation: {datetime.datetime.now() - a}')\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZGtCnw8Bz_e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhQcpNHhwifD"
      },
      "source": [
        "# pred_probabilities = model.predict(validation_set)\n",
        "# pred_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIaXd3MAN-HG"
      },
      "source": [
        "# pd.Series(pred_probabilities.flatten()).hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph7bxOwswilc"
      },
      "source": [
        "# predictions = pred_probabilities > 0.5\n",
        "# predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCij-z6Ixbke"
      },
      "source": [
        "# from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlhww4lYxbrv"
      },
      "source": [
        "# print(classification_report(test_image_gen.classes,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K895sFasxbuR"
      },
      "source": [
        "# Map = train_image_gen.class_indices\n",
        "# print(pd.DataFrame(confusion_matrix(predictions,test_image_gen.classes),\n",
        "#         columns=[ [\"Actual \" + sub for sub in Map] ], \n",
        "#         index = [ [\"Prediction \" + sub for sub in Map ]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RBA37jAyt_n"
      },
      "source": [
        "# confusion_matrix(predictions,test_image_gen.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QcJwkNZwhYY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtuBjjzFiQRh"
      },
      "source": [
        "predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33eISGfPciHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyoYr7K-cim0"
      },
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# model = load_model('outputs/model/malaria_detector.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO9FlZAmcipe"
      },
      "source": [
        "# model.summary()\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Y7A-PIdUR3"
      },
      "source": [
        "pointer = 66\n",
        "label = labels[1]\n",
        "para_img = imread(test_path + '/'+ label + '/'+ os.listdir(test_path+'/'+ label)[pointer])\n",
        "print(para_img.shape)\n",
        "sns.set_style(\"white\")\n",
        "plt.imshow(para_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-6fVsJslzCR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz-NL2mXaczH"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[1]\n",
        "my_image = image.load_img(test_path + '/'+ label + '/'+ os.listdir(test_path+'/'+ label)[pointer],\n",
        "                          target_size=image_shape,\n",
        "                          color_mode='rgb')\n",
        "print(my_image.size, my_image.mode)\n",
        "my_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwoIvJWQcitQ"
      },
      "source": [
        "sns.set_style(\"white\")\n",
        "\n",
        "my_image = image.img_to_array(my_image)\n",
        "print(my_image.shape,my_image.max())\n",
        "plt.imshow(my_image)\n",
        "plt.show()\n",
        "\n",
        "# my_image = np.expand_dims(my_image, axis=0)\n",
        "\n",
        "\n",
        "# import cv2\n",
        "# img_resized = cv2.resize(para_img,(image_shape[1], image_shape[0]))   # change for dynamic\n",
        "# print(img_resized.shape)\n",
        "# sns.set_style(\"white\")\n",
        "# plt.imshow(img_resized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkFoAMtUdEO2"
      },
      "source": [
        "pred_proba = model.predict(my_image)[0,0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class =  target_map[pred_proba > 0.5]  \n",
        "\n",
        "if pred_class == target_map[0]: pred_proba = 1 - pred_proba\n",
        "\n",
        "print(pred_proba)\n",
        "print(pred_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHV2zyFU5sIG"
      },
      "source": [
        "# prob_from_predicted_class = round(pred_proba[0,0], 2)\n",
        "# prob_from_other_class = round(1 - pred_proba[0,0], 2)\n",
        "# print(prob_from_predicted_class,prob_from_other_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA1fUD4c4mQz"
      },
      "source": [
        "prob_per_class= pd.DataFrame(data=[0,0],index=train_set.class_indices.keys(), columns=['Probability'])\n",
        "\n",
        "prob_per_class.loc[pred_class] = pred_proba\n",
        "\n",
        "for x in prob_per_class.index.to_list():\n",
        "  if x not in pred_class: prob_per_class.loc[x] = 1 - pred_proba\n",
        "\n",
        "prob_per_class = prob_per_class.round(3)\n",
        "print(prob_per_class)\n",
        "import plotly.express as px\n",
        "fig = px.bar(prob_per_class, x = prob_per_class.index, y = prob_per_class['Probability'],range_y=[0,1],\n",
        "             labels=dict(x=\"Diagnosis\"), width=400, height=500)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN4DTer0e3r0"
      },
      "source": [
        "save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-XFd3CV0GRs"
      },
      "source": [
        "model.save('/content/WalkthroughProject01/outputs/model/model_full_train_set.h5')  # creates a HDF5 file 'my_model.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFqIpblnaDI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c60wT9Nvnaht"
      },
      "source": [
        "# save modeel history - 2 plots\n",
        "# save classification report? confusion matrix?or predictions on train,val,test sets?\n",
        "# train_set.class_indices\n",
        "# image_shape \n",
        "# save avg image, std image,\n",
        "# labels frequency on train, vali, test sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcmA1wG8AdC"
      },
      "source": [
        "# **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Nrg1IgeQMD"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1kUQ0VIoi4c"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dafOBor8OoM"
      },
      "source": [
        "CommitMsg = \"update\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkyUs70oloW"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0NCb8-L8Vr1"
      },
      "source": [
        "!git push origin main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    }
  ]
}